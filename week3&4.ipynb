{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Initial load: 168,919 records\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv('data/processed/amazon_reviews_with_metadata.csv')\n",
        "\n",
        "print(f\"  Initial load: {len(df):,} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Final records: 16,379\n",
            "  Shape: (16379, 19)\n",
            "  Filtering removed NaN, empty strings, and 'Unknown Product' titles\n"
          ]
        }
      ],
      "source": [
        "df = df[\n",
        "    df['title_clean'].notna() & \n",
        "    (df['title_clean'].astype(str) != 'nan') &\n",
        "    (df['title_clean'].astype(str).str.strip() != '') &\n",
        "    (df['title_clean'] != 'Unknown Product') & \n",
        "    df['reviewText_clean'].notna() &\n",
        "    (df['reviewText_clean'].astype(str) != 'nan') &\n",
        "    (df['reviewText_clean'].astype(str).str.strip() != '')\n",
        "].copy()\n",
        "\n",
        "print(f\"  Final records: {len(df):,}\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Filtering removed NaN, empty strings, and 'Unknown Product' titles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  All rows have title: True\n",
            "  All rows have review text: True\n"
          ]
        }
      ],
      "source": [
        "title_check = df['title_clean'].notna().all() and (df['title_clean'].astype(str) != 'nan').all()\n",
        "review_check = df['reviewText_clean'].notna().all() and (df['reviewText_clean'].astype(str) != 'nan').all()\n",
        "print(f\"  All rows have title: {title_check}\")\n",
        "print(f\"  All rows have review text: {review_check}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewText_clean</th>\n",
              "      <th>summary_clean</th>\n",
              "      <th>reviewTime_dt</th>\n",
              "      <th>title_clean</th>\n",
              "      <th>description_clean</th>\n",
              "      <th>price</th>\n",
              "      <th>brand</th>\n",
              "      <th>main_category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>data_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AES2AZFVTXKBZ</td>\n",
              "      <td>1400532620</td>\n",
              "      <td>Amazon Customer \"Charge It\"</td>\n",
              "      <td>[2, 3]</td>\n",
              "      <td>Highly disappointed. I purchased the new B/W t...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Not for Students and Professors</td>\n",
              "      <td>1310947200</td>\n",
              "      <td>07 18, 2011</td>\n",
              "      <td>Highly disappointed. I purchased the new B/W t...</td>\n",
              "      <td>Not for Students and Professors</td>\n",
              "      <td>2011-07-18</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3G</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
              "      <td>74.9500</td>\n",
              "      <td>Barnes &amp;amp; Noble</td>\n",
              "      <td>eBook Readers &amp; Accessories</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1QPUBF6U5EQM6</td>\n",
              "      <td>1400532620</td>\n",
              "      <td>Dare2Dream</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>When I purchased this item it was still runnin...</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>Not Sure I'd Do It Over Again</td>\n",
              "      <td>1322265600</td>\n",
              "      <td>11 26, 2011</td>\n",
              "      <td>When I purchased this item it was still runnin...</td>\n",
              "      <td>Not Sure I'd Do It Over Again</td>\n",
              "      <td>2011-11-26</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3G</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
              "      <td>74.9500</td>\n",
              "      <td>Barnes &amp;amp; Noble</td>\n",
              "      <td>eBook Readers &amp; Accessories</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3OEKYU0C8ZXAO</td>\n",
              "      <td>1400532620</td>\n",
              "      <td>joon</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I loved using this nook reader. The bottom tou...</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>Great reader</td>\n",
              "      <td>1307059200</td>\n",
              "      <td>06 3, 2011</td>\n",
              "      <td>I loved using this nook reader. The bottom tou...</td>\n",
              "      <td>Great reader</td>\n",
              "      <td>2011-06-03</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3G</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
              "      <td>74.9500</td>\n",
              "      <td>Barnes &amp;amp; Noble</td>\n",
              "      <td>eBook Readers &amp; Accessories</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1S71JIN40YHXK</td>\n",
              "      <td>1400532620</td>\n",
              "      <td>Pamela</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I ordered this product and it was not what I w...</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>Nook</td>\n",
              "      <td>1369872000</td>\n",
              "      <td>05 30, 2013</td>\n",
              "      <td>I ordered this product and it was not what I w...</td>\n",
              "      <td>Nook</td>\n",
              "      <td>2013-05-30</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3G</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
              "      <td>74.9500</td>\n",
              "      <td>Barnes &amp;amp; Noble</td>\n",
              "      <td>eBook Readers &amp; Accessories</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A10BOETDPAFJ4C</td>\n",
              "      <td>1400532620</td>\n",
              "      <td>weapon x</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>the battery is great-about 12-14 hours from 80...</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>Love it!!</td>\n",
              "      <td>1302480000</td>\n",
              "      <td>04 11, 2011</td>\n",
              "      <td>the battery is great-about 12-14 hours from 80...</td>\n",
              "      <td>Love it!!</td>\n",
              "      <td>2011-04-11</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3G</td>\n",
              "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
              "      <td>74.9500</td>\n",
              "      <td>Barnes &amp;amp; Noble</td>\n",
              "      <td>eBook Readers &amp; Accessories</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin                 reviewerName helpful  \\\n",
              "0   AES2AZFVTXKBZ  1400532620  Amazon Customer \"Charge It\"  [2, 3]   \n",
              "1  A1QPUBF6U5EQM6  1400532620                   Dare2Dream  [1, 1]   \n",
              "2  A3OEKYU0C8ZXAO  1400532620                         joon  [0, 0]   \n",
              "3  A1S71JIN40YHXK  1400532620                       Pamela  [0, 0]   \n",
              "4  A10BOETDPAFJ4C  1400532620                     weapon x  [1, 1]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  Highly disappointed. I purchased the new B/W t...   1.0000   \n",
              "1  When I purchased this item it was still runnin...   4.0000   \n",
              "2  I loved using this nook reader. The bottom tou...   5.0000   \n",
              "3  I ordered this product and it was not what I w...   5.0000   \n",
              "4  the battery is great-about 12-14 hours from 80...   5.0000   \n",
              "\n",
              "                           summary  unixReviewTime   reviewTime  \\\n",
              "0  Not for Students and Professors      1310947200  07 18, 2011   \n",
              "1    Not Sure I'd Do It Over Again      1322265600  11 26, 2011   \n",
              "2                     Great reader      1307059200   06 3, 2011   \n",
              "3                             Nook      1369872000  05 30, 2013   \n",
              "4                        Love it!!      1302480000  04 11, 2011   \n",
              "\n",
              "                                    reviewText_clean  \\\n",
              "0  Highly disappointed. I purchased the new B/W t...   \n",
              "1  When I purchased this item it was still runnin...   \n",
              "2  I loved using this nook reader. The bottom tou...   \n",
              "3  I ordered this product and it was not what I w...   \n",
              "4  the battery is great-about 12-14 hours from 80...   \n",
              "\n",
              "                     summary_clean reviewTime_dt  \\\n",
              "0  Not for Students and Professors    2011-07-18   \n",
              "1    Not Sure I'd Do It Over Again    2011-11-26   \n",
              "2                     Great reader    2011-06-03   \n",
              "3                             Nook    2013-05-30   \n",
              "4                        Love it!!    2011-04-11   \n",
              "\n",
              "                           title_clean  \\\n",
              "0  Barnes & Noble Nook eReader - no 3G   \n",
              "1  Barnes & Noble Nook eReader - no 3G   \n",
              "2  Barnes & Noble Nook eReader - no 3G   \n",
              "3  Barnes & Noble Nook eReader - no 3G   \n",
              "4  Barnes & Noble Nook eReader - no 3G   \n",
              "\n",
              "                                   description_clean   price  \\\n",
              "0  Barnes & Noble Nook eReader - no 3GMeet nook. ... 74.9500   \n",
              "1  Barnes & Noble Nook eReader - no 3GMeet nook. ... 74.9500   \n",
              "2  Barnes & Noble Nook eReader - no 3GMeet nook. ... 74.9500   \n",
              "3  Barnes & Noble Nook eReader - no 3GMeet nook. ... 74.9500   \n",
              "4  Barnes & Noble Nook eReader - no 3GMeet nook. ... 74.9500   \n",
              "\n",
              "                brand                main_category subcategory data_source  \n",
              "0  Barnes &amp; Noble  eBook Readers & Accessories     Unknown      Amazon  \n",
              "1  Barnes &amp; Noble  eBook Readers & Accessories     Unknown      Amazon  \n",
              "2  Barnes &amp; Noble  eBook Readers & Accessories     Unknown      Amazon  \n",
              "3  Barnes &amp; Noble  eBook Readers & Accessories     Unknown      Amazon  \n",
              "4  Barnes &amp; Noble  eBook Readers & Accessories     Unknown      Amazon  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert reviewTime to datetime\n",
        "df['reviewTime_dt'] = pd.to_datetime(df['reviewTime'], format='%m %d, %Y')\n",
        "df['review_year'] = df['reviewTime_dt'].dt.year\n",
        "df['review_month'] = df['reviewTime_dt'].dt.month\n",
        "df['review_day_of_week'] = df['reviewTime_dt'].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_date = df['reviewTime_dt'].min()\n",
        "df['days_since_start'] = (df['reviewTime_dt'] - min_date).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_days = df['days_since_start'].max()\n",
        "df['time_weight'] = (df['days_since_start'] / max_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['helpful_votes'] = df['helpful'].apply(\n",
        "    lambda x: eval(x)[0] if isinstance(x, str) else (x[0] if isinstance(x, list) else 0)\n",
        ")\n",
        "df['total_votes'] = df['helpful'].apply(\n",
        "    lambda x: eval(x)[1] if isinstance(x, str) else (x[1] if isinstance(x, list) else 0)\n",
        ")\n",
        "df['helpful_ratio'] = df.apply(\n",
        "    lambda row: row['helpful_votes'] / row['total_votes'] if row['total_votes'] > 0 else 0,\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['review_length'] = df['reviewText_clean'].str.len()\n",
        "df['review_length_normalized'] = (df['review_length'] - df['review_length'].min()) / \\\n",
        "                                  (df['review_length'].max() - df['review_length'].min())\n",
        "\n",
        "df['implicit_rating'] = (\n",
        "    df['overall'] * 0.7 +\n",
        "    df['helpful_ratio'] * 5 * 0.15 +\n",
        "    df['review_length_normalized'] * 5 * 0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average review length: 652 characters\n",
            "Average helpful ratio: 0.331\n",
            "Implicit rating range: 0.70 - 4.93\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average review length: {df['review_length'].mean():.0f} characters\")\n",
        "print(f\"Average helpful ratio: {df['helpful_ratio'].mean():.3f}\")\n",
        "print(f\"Implicit rating range: {df['implicit_rating'].min():.2f} - {df['implicit_rating'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# User-level features\n",
        "user_stats = df.groupby('reviewerID').agg({\n",
        "    'overall': ['mean', 'std', 'count'],\n",
        "    'asin': 'nunique'\n",
        "}).reset_index()\n",
        "user_stats.columns = ['reviewerID', 'user_avg_rating', 'user_rating_std', \n",
        "                      'user_review_count', 'user_products_reviewed']\n",
        "user_stats['user_rating_std'] = user_stats['user_rating_std'].fillna(0)\n",
        "\n",
        "df = df.merge(user_stats, on='reviewerID', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reviews per user: 1.16\n",
            "Average reviews per product: 20.80\n",
            "Users who reviewed multiple products: 2,022\n"
          ]
        }
      ],
      "source": [
        "# Product-level features\n",
        "product_stats = df.groupby('asin').agg({\n",
        "    'overall': ['mean', 'std', 'count'],\n",
        "    'reviewerID': 'nunique'\n",
        "}).reset_index()\n",
        "product_stats.columns = ['asin', 'product_avg_rating', 'product_rating_std',\n",
        "                         'product_review_count', 'product_unique_reviewers']\n",
        "product_stats['product_rating_std'] = product_stats['product_rating_std'].fillna(0)\n",
        "\n",
        "df = df.merge(product_stats, on='asin', how='left')\n",
        "\n",
        "print(f\"Average reviews per user: {df['user_review_count'].mean():.2f}\")\n",
        "print(f\"Average reviews per product: {df['product_review_count'].mean():.2f}\")\n",
        "print(f\"Users who reviewed multiple products: {(df['user_products_reviewed'] > 1).sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix shape: (5231, 500)\n",
            "Vocabulary size: 500\n",
            "Sparsity: 94.57%\n"
          ]
        }
      ],
      "source": [
        "# Combine title and description\n",
        "df['product_text'] = df['title_clean'].fillna('') + ' ' + df['description_clean'].fillna('')\n",
        "\n",
        "# Create TF-IDF vectorizer for products\n",
        "product_tfidf = TfidfVectorizer(\n",
        "    max_features=500,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2, \n",
        "    max_df=0.8\n",
        ")\n",
        "\n",
        "product_texts = df.groupby('asin')['product_text'].first().reset_index()\n",
        "product_tfidf_matrix = product_tfidf.fit_transform(product_texts['product_text'])\n",
        "\n",
        "print(f\"Matrix shape: {product_tfidf_matrix.shape}\")\n",
        "print(f\"Vocabulary size: {len(product_tfidf.vocabulary_)}\")\n",
        "print(f\"Sparsity: {(1 - product_tfidf_matrix.nnz / (product_tfidf_matrix.shape[0] * product_tfidf_matrix.shape[1]))*100:.2f}%\")\n",
        "\n",
        "product_to_idx = {asin: idx for idx, asin in enumerate(product_texts['asin'])}\n",
        "idx_to_product = {idx: asin for asin, idx in product_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Creating TF-IDF vectors for review text...\n",
            "  Sample size: 10,000\n",
            "  Matrix shape: (10000, 300)\n",
            "  Vocabulary size: 300\n"
          ]
        }
      ],
      "source": [
        "print(\"  Creating TF-IDF vectors for review text...\")\n",
        "review_tfidf = TfidfVectorizer(\n",
        "    max_features=300,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=3,\n",
        "    max_df=0.7\n",
        ")\n",
        "\n",
        "review_sample = df['reviewText_clean'].head(min(10000, len(df)))\n",
        "review_tfidf_matrix = review_tfidf.fit_transform(review_sample)\n",
        "\n",
        "print(f\"  Sample size: {len(review_sample):,}\")\n",
        "print(f\"  Matrix shape: {review_tfidf_matrix.shape}\")\n",
        "print(f\"  Vocabulary size: {len(review_tfidf.vocabulary_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matrix dimensions:\n",
            "  Users: 15,290\n",
            "  Products: 5,231\n",
            "  Possible interactions: 79,981,990\n",
            "  Actual interactions: 16,379\n"
          ]
        }
      ],
      "source": [
        "user_ids = df['reviewerID'].unique()\n",
        "product_ids = df['asin'].unique()\n",
        "\n",
        "user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
        "product_to_idx_matrix = {product: idx for idx, product in enumerate(product_ids)}\n",
        "\n",
        "print(f\"\\nMatrix dimensions:\")\n",
        "print(f\"  Users: {len(user_ids):,}\")\n",
        "print(f\"  Products: {len(product_ids):,}\")\n",
        "print(f\"  Possible interactions: {len(user_ids) * len(product_ids):,}\")\n",
        "print(f\"  Actual interactions: {len(df):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Sparsity: 99.98%\n"
          ]
        }
      ],
      "source": [
        "sparsity = 1 - (len(df) / (len(user_ids) * len(product_ids)))\n",
        "print(f\"  Sparsity: {sparsity * 100:.2f}%\")\n",
        "\n",
        "df['user_idx'] = df['reviewerID'].map(user_to_idx)\n",
        "df['product_idx'] = df['asin'].map(product_to_idx_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_size=0.2 \n",
        "min_user_interactions=2\n",
        "\n",
        "user_counts = df['reviewerID'].value_counts()\n",
        "valid_users = user_counts[user_counts >= min_user_interactions].index\n",
        "df_filtered = df[df['reviewerID'].isin(valid_users)].copy()\n",
        "\n",
        "df_filtered = df_filtered.sort_values('reviewTime_dt').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Split results:\n",
            "  Train: 1,089 (53.9%)\n",
            "  Test:  933 (46.1%)\n",
            "\n",
            "  Train users: 933\n",
            "  Test users:  933\n",
            "  Train products: 823\n",
            "  Test products:  684\n",
            "\n",
            "  Product overlap: 188 (27.5% of test products)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for user_id in df_filtered['reviewerID'].unique():\n",
        "    user_data = df_filtered[df_filtered['reviewerID'] == user_id].sort_values('reviewTime_dt')\n",
        "    n_user_items = len(user_data)\n",
        "    n_test = max(1, int(n_user_items * test_size))\n",
        "    \n",
        "    train_data.append(user_data.iloc[:-n_test])\n",
        "    test_data.append(user_data.iloc[-n_test:])\n",
        "\n",
        "train_df = pd.concat(train_data, ignore_index=True)\n",
        "test_df = pd.concat(test_data, ignore_index=True)\n",
        "\n",
        "print(f\"\\nSplit results:\")\n",
        "print(f\"  Train: {len(train_df):,} ({len(train_df)/len(df_filtered)*100:.1f}%)\")\n",
        "print(f\"  Test:  {len(test_df):,} ({len(test_df)/len(df_filtered)*100:.1f}%)\")\n",
        "print(f\"\\n  Train users: {train_df['reviewerID'].nunique():,}\")\n",
        "print(f\"  Test users:  {test_df['reviewerID'].nunique():,}\")\n",
        "print(f\"  Train products: {train_df['asin'].nunique():,}\")\n",
        "print(f\"  Test products:  {test_df['asin'].nunique():,}\")\n",
        "\n",
        "train_products = set(train_df['asin'].unique())\n",
        "test_products = set(test_df['asin'].unique())\n",
        "overlap = len(train_products & test_products)\n",
        "print(f\"\\n  Product overlap: {overlap:,} ({overlap/len(test_products)*100:.1f}% of test products)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1: Popularity-Based Recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Popular Products:\n",
            "  Roku 3 Streaming Media Player...\n",
            "    Rating: 4.88, Reviews: 8, Score: 10.71\n",
            "  Belkin 3-Outlet Mini Travel Swivel Charger Surge Protector w...\n",
            "    Rating: 4.62, Reviews: 8, Score: 10.16\n",
            "  Transcend 4 GB Class 6 SDHC Flash Memory Card TS4GSDHC6...\n",
            "    Rating: 4.71, Reviews: 7, Score: 9.80\n",
            "  Crucial m4 64GB 2.5-Inch (9.5mm) SATA 6Gb/s Solid State Driv...\n",
            "    Rating: 5.00, Reviews: 6, Score: 9.73\n",
            "  Garmin nuvi 350 3.5-Inch Portable GPS Navigator (Discontinue...\n",
            "    Rating: 4.22, Reviews: 9, Score: 9.72\n",
            "  AmazonBasics Hard Carrying Case for My Passport Essential - ...\n",
            "    Rating: 4.57, Reviews: 7, Score: 9.51\n",
            "  Linksys E1200 Wireless-N300 Router...\n",
            "    Rating: 4.11, Reviews: 9, Score: 9.47\n",
            "  eneloop SEC-CSPACER4PK C Size Spacers for use with AA batter...\n",
            "    Rating: 4.50, Reviews: 6, Score: 8.76\n",
            "  Logitech Wireless Touch Keyboard K400 with Built-In Multi-To...\n",
            "    Rating: 4.80, Reviews: 5, Score: 8.60\n",
            "  Flip MinoHD Video Camera - Brushed Metal, 8 GB, 2 Hours (2nd...\n",
            "    Rating: 4.17, Reviews: 6, Score: 8.11\n"
          ]
        }
      ],
      "source": [
        "class PopularityRecommender:\n",
        "    def __init__(self):\n",
        "        self.popular_items = None\n",
        "    \n",
        "    def fit(self, df):\n",
        "        popularity = df.groupby('asin').agg({\n",
        "            'overall': ['mean', 'count']\n",
        "        }).reset_index()\n",
        "        popularity.columns = ['asin', 'avg_rating', 'review_count']\n",
        "        \n",
        "        # Weighted score: (avg_rating * log(count))\n",
        "        popularity['popularity_score'] = (\n",
        "            popularity['avg_rating'] * np.log1p(popularity['review_count'])\n",
        "        )\n",
        "        \n",
        "        self.popular_items = popularity.sort_values(\n",
        "            'popularity_score', ascending=False\n",
        "        )\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def recommend(self, user_id=None, n=10, exclude_items=None):\n",
        "        recommendations = self.popular_items.head(n + (len(exclude_items) if exclude_items else 0))\n",
        "        \n",
        "        if exclude_items:\n",
        "            recommendations = recommendations[~recommendations['asin'].isin(exclude_items)]\n",
        "        \n",
        "        return recommendations.head(n)['asin'].tolist()\n",
        "\n",
        "pop_model = PopularityRecommender()\n",
        "pop_model.fit(train_df)\n",
        "\n",
        "print(f\"\\nTop 10 Popular Products:\")\n",
        "top_10 = pop_model.popular_items.head(10)\n",
        "for idx, row in top_10.iterrows():\n",
        "    product_name = train_df[train_df['asin'] == row['asin']]['title_clean'].iloc[0][:60]\n",
        "    print(f\"  {product_name}...\")\n",
        "    print(f\"    Rating: {row['avg_rating']:.2f}, Reviews: {row['review_count']}, Score: {row['popularity_score']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2: Collaborative Filtering (SVD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training collaborative filtering model...\n",
            "\n",
            "Preparing data for SVD...\n",
            "  Users: 933\n",
            "  Items: 823\n",
            "  Ratings: 1,089\n",
            "\n",
            "Training SVD model...\n",
            "  Latent factors: 5\n",
            "\n",
            " SVD model trained\n",
            "  User factors shape: (933, 5)\n",
            "  Item factors shape: (823, 5)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.MatrixFactorizationSVD at 0x14f878640>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MatrixFactorizationSVD:\n",
        "\n",
        "    def __init__(self, n_factors=5):\n",
        "        self.n_factors = 5\n",
        "        self.user_factors = None\n",
        "        self.item_factors = None\n",
        "        self.global_mean = None\n",
        "        self.user_bias = None\n",
        "        self.item_bias = None\n",
        "        self.user_to_idx = None\n",
        "        self.item_to_idx = None\n",
        "        self.idx_to_user = None\n",
        "        self.idx_to_item = None\n",
        "    \n",
        "    def fit(self, train_df, user_col='reviewerID', item_col='asin', rating_col='overall'):\n",
        "        \"\"\"\n",
        "        Train SVD model on training data\n",
        "        \"\"\"\n",
        "        print(\"\\nPreparing data for SVD...\")\n",
        "        \n",
        "        # Create user and item mappings\n",
        "        users = train_df[user_col].unique()\n",
        "        items = train_df[item_col].unique()\n",
        "        \n",
        "        self.user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
        "        self.item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
        "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
        "        self.idx_to_item = {idx: item for item, idx in self.item_to_idx.items()}\n",
        "        \n",
        "        n_users = len(users)\n",
        "        n_items = len(items)\n",
        "        \n",
        "        print(f\"  Users: {n_users:,}\")\n",
        "        print(f\"  Items: {n_items:,}\")\n",
        "        print(f\"  Ratings: {len(train_df):,}\")\n",
        "        \n",
        "        # Create user-item rating matrix\n",
        "        user_indices = train_df[user_col].map(self.user_to_idx).values\n",
        "        item_indices = train_df[item_col].map(self.item_to_idx).values\n",
        "        ratings = train_df[rating_col].values\n",
        "        \n",
        "        rating_matrix = csr_matrix(\n",
        "            (ratings, (user_indices, item_indices)),\n",
        "            shape=(n_users, n_items)\n",
        "        )\n",
        "        \n",
        "        # Calculate global mean and biases\n",
        "        self.global_mean = ratings.mean()\n",
        "        \n",
        "        # User biases\n",
        "        user_ratings = train_df.groupby(user_col)[rating_col].mean()\n",
        "        self.user_bias = {user: rating - self.global_mean \n",
        "                         for user, rating in user_ratings.items()}\n",
        "        \n",
        "        # Item biases\n",
        "        item_ratings = train_df.groupby(item_col)[rating_col].mean()\n",
        "        self.item_bias = {item: rating - self.global_mean \n",
        "                         for item, rating in item_ratings.items()}\n",
        "        \n",
        "        # Perform SVD\n",
        "        print(\"\\nTraining SVD model...\")\n",
        "        print(f\"  Latent factors: {self.n_factors}\")\n",
        "        \n",
        "        U, sigma, Vt = svds(rating_matrix, k=self.n_factors)\n",
        "        \n",
        "        self.user_factors = U\n",
        "        self.item_factors = Vt.T\n",
        "        self.sigma = sigma\n",
        "        \n",
        "        print(\"\\n SVD model trained\")\n",
        "        print(f\"  User factors shape: {self.user_factors.shape}\")\n",
        "        print(f\"  Item factors shape: {self.item_factors.shape}\")\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Predict rating for a user-item pair\n",
        "        \"\"\"\n",
        "        if user_id not in self.user_to_idx:\n",
        "            return self.global_mean + self.item_bias.get(item_id, 0)\n",
        "        \n",
        "        if item_id not in self.item_to_idx:\n",
        "            return self.global_mean + self.user_bias.get(user_id, 0)\n",
        "        \n",
        "        user_idx = self.user_to_idx[user_id]\n",
        "        item_idx = self.item_to_idx[item_id]\n",
        "        \n",
        "        baseline = self.global_mean + \\\n",
        "                  self.user_bias.get(user_id, 0) + \\\n",
        "                  self.item_bias.get(item_id, 0)\n",
        "        \n",
        "        interaction = np.dot(self.user_factors[user_idx], self.item_factors[item_idx])\n",
        "        \n",
        "        prediction = baseline + interaction\n",
        "        \n",
        "        return np.clip(prediction, 1, 5)\n",
        "\n",
        "print(\"\\nTraining collaborative filtering model...\")\n",
        "svd_model = MatrixFactorizationSVD(n_factors=50)\n",
        "svd_model.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 recommendations for user 'A3TUZOJZM9008Y':\n",
            "  1. Cisco-Linksys PS2KVMSK ProConnect 2-Port Compact KVM Switch ... (predicted rating: 5.00)\n",
            "  2. Lexar Media 128 MB Memory Stick... (predicted rating: 5.00)\n",
            "  3. Canon EF 135mm f/2L USM Lens for Canon SLR Cameras... (predicted rating: 5.00)\n",
            "  4. Winegard FV-HD30 FreeVision HDTV Antenna (Discontinued by Ma... (predicted rating: 5.00)\n",
            "  5. Kanex HDMIMINI6feet High Speed Mini HDMI Cable (6 feet)... (predicted rating: 5.00)\n",
            "  6. SanDisk SDSM-128-A10 SmartMedia 128 MB... (predicted rating: 5.00)\n",
            "  7. Canon EOS-1Ds 11.1MP Digital SLR Camera (Body Only)... (predicted rating: 5.00)\n",
            "  8. Apple iPod shuffle 512 MB White (1st Generation) (Discontinu... (predicted rating: 5.00)\n",
            "  9. Logitech Quickcam Orbit WebCam... (predicted rating: 5.00)\n",
            "  10. Logitech Harmony H-688 Universal Remote Control (Silver) (Di... (predicted rating: 5.00)\n"
          ]
        }
      ],
      "source": [
        "def get_svd_recommendations(user_id, n=10, exclude_items=None):\n",
        "    \"\"\"\n",
        "    Get top N recommendations for a user using SVD\n",
        "    \"\"\"\n",
        "    all_products = train_df['asin'].unique()\n",
        "    \n",
        "    # Get products user hasn't interacted with\n",
        "    user_items = set(train_df[train_df['reviewerID'] == user_id]['asin'])\n",
        "    unseen_products = [p for p in all_products if p not in user_items]\n",
        "    \n",
        "    if exclude_items:\n",
        "        unseen_products = [p for p in unseen_products if p not in exclude_items]\n",
        "    \n",
        "    predictions = []\n",
        "    for product_id in unseen_products:\n",
        "        pred_rating = svd_model.predict(user_id, product_id)\n",
        "        predictions.append((product_id, pred_rating))\n",
        "    \n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return [p[0] for p in predictions[:n]]\n",
        "\n",
        "sample_user = train_df['reviewerID'].iloc[0]\n",
        "svd_recs = get_svd_recommendations(sample_user, n=10)\n",
        "\n",
        "print(f\"\\nTop 10 recommendations for user '{sample_user}':\")\n",
        "for i, asin in enumerate(svd_recs, 1):\n",
        "    if asin in df['asin'].values:\n",
        "        product_name = df[df['asin'] == asin]['title_clean'].iloc[0][:60]\n",
        "        pred_rating = svd_model.predict(sample_user, asin)\n",
        "        print(f\"  {i}. {product_name}... (predicted rating: {pred_rating:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 3: Content-Based Filtering (KNN on TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Using TF-IDF matrix: (5231, 500)\n",
            "  KNN neighbors: 20\n"
          ]
        }
      ],
      "source": [
        "class ContentBasedRecommender:\n",
        "    def __init__(self, tfidf_matrix, product_mapping):\n",
        "        self.tfidf_matrix = tfidf_matrix\n",
        "        self.product_mapping = product_mapping\n",
        "        self.knn_model = None\n",
        "    \n",
        "    def fit(self):\n",
        "        self.knn_model = NearestNeighbors(\n",
        "            n_neighbors=20,\n",
        "            metric='cosine',\n",
        "            algorithm='brute'\n",
        "        )\n",
        "        self.knn_model.fit(self.tfidf_matrix)\n",
        "        return self\n",
        "    \n",
        "    def recommend_similar(self, product_id, n=10):\n",
        "        if product_id not in self.product_mapping:\n",
        "            return []\n",
        "        \n",
        "        product_idx = self.product_mapping[product_id]\n",
        "        product_vector = self.tfidf_matrix[product_idx]\n",
        "        \n",
        "        # Find k nearest neighbors\n",
        "        distances, indices = self.knn_model.kneighbors(\n",
        "            product_vector, \n",
        "            n_neighbors=n+1\n",
        "        )\n",
        "        \n",
        "        similar_indices = indices[0][1:]\n",
        "        \n",
        "        idx_to_product_local = {idx: pid for pid, idx in self.product_mapping.items()}\n",
        "        similar_products = [idx_to_product_local[idx] for idx in similar_indices]\n",
        "        \n",
        "        return similar_products\n",
        "\n",
        "content_model = ContentBasedRecommender(product_tfidf_matrix, product_to_idx)\n",
        "content_model.fit()\n",
        "\n",
        "print(f\"  Using TF-IDF matrix: {product_tfidf_matrix.shape}\")\n",
        "print(f\"  KNN neighbors: 20\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "For product: 'Barnes & Noble Nook eReader - no 3G...'\n",
            "\n",
            "Top 10 similar products:\n",
            "  1. NETGEAR AC1600 Dual Band Wi-Fi Gigabit Router (R6250)...\n",
            "  2. Honeywell L5100-WIFI - L5100 Wifi Module for Lynx Touch 5100...\n",
            "  3. Patriot Box Office Wireless N USB Adapter PCBOWAU2-N...\n",
            "  4. Grace Digital Wi-Fi Music Player with 3.5-Inch Color Display...\n",
            "  5. Amped Wireless High Power 1000mW Wi-Fi Signal Booster (SB100...\n",
            "  6. TRENDnet N300 Wireless High Power Easy-N Range Stand Alone W...\n",
            "  7. NETGEAR N300 Wi-Fi Range Extender - Wall Plug Version (WN300...\n",
            "  8. D-Link Wireless Dual Band N 300+ Mbps Wi-Fi Gigabit Range Ex...\n",
            "  9. NETGEAR Dual Band Wi-Fi Range Extender - Desktop Version wit...\n",
            "  10. MSI X320-037US 13.4-Inch Laptop - Black...\n"
          ]
        }
      ],
      "source": [
        "sample_product = df['asin'].iloc[0]\n",
        "sample_title = df[df['asin'] == sample_product]['title_clean'].iloc[0][:60]\n",
        "\n",
        "content_recs = content_model.recommend_similar(sample_product, n=10)\n",
        "\n",
        "print(f\"\\nFor product: '{sample_title}...'\")\n",
        "print(f\"\\nTop 10 similar products:\")\n",
        "for i, asin in enumerate(content_recs, 1):\n",
        "    if asin in df['asin'].values:\n",
        "        product_name = df[df['asin'] == asin]['title_clean'].iloc[0][:60]\n",
        "        print(f\"  {i}. {product_name}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_recommendations(model, train_df, test_df, model_type='svd', \n",
        "                            k_values=[5, 10, 20], min_rating_threshold=3.5):\n",
        "    \n",
        "    test_users = test_df['reviewerID'].unique()\n",
        "    print(f\"\\nEvaluating on {len(test_users):,} users\")\n",
        "    \n",
        "    results = {\n",
        "        'predictions': [],\n",
        "        'actuals': [],\n",
        "        'hit_rates': {k: [] for k in k_values},\n",
        "        'precisions': {k: [] for k in k_values},\n",
        "        'recalls': {k: [] for k in k_values},\n",
        "        'ndcg': {k: [] for k in k_values}\n",
        "    }\n",
        "    \n",
        "    users_evaluated = 0\n",
        "    \n",
        "    for user_id in test_users:\n",
        "        user_test = test_df[test_df['reviewerID'] == user_id]\n",
        "        user_train = train_df[train_df['reviewerID'] == user_id]\n",
        "        \n",
        "        if len(user_train) == 0:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            if model_type == 'svd':\n",
        "                train_items = set(user_train['asin'])\n",
        "                all_train_items = set(train_df['asin'].unique())\n",
        "                candidate_items = list(all_train_items - train_items)\n",
        "                \n",
        "                predictions = []\n",
        "                for item in candidate_items:\n",
        "                    pred_rating = model.predict(user_id, item)\n",
        "                    predictions.append((item, pred_rating))\n",
        "                \n",
        "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "                recommended_items = [item for item, rating in predictions[:max(k_values)]]\n",
        "                \n",
        "            elif model_type == 'popularity':\n",
        "                train_items = set(user_train['asin'])\n",
        "                recommended_items = model.recommend(n=max(k_values), exclude_items=train_items)\n",
        "                \n",
        "            else:\n",
        "                seed_items = user_train[user_train['overall'] >= 4.0]['asin'].values\n",
        "                if len(seed_items) == 0:\n",
        "                    continue\n",
        "                seed_item = seed_items[-1]\n",
        "                recommended_items = model.recommend_similar(seed_item, n=max(k_values))\n",
        "            \n",
        "        except Exception as e:\n",
        "            continue\n",
        "        \n",
        "        relevant_items = set(user_test[user_test['overall'] >= min_rating_threshold]['asin'])\n",
        "        \n",
        "        if len(relevant_items) == 0:\n",
        "            continue\n",
        "        \n",
        "        for k in k_values:\n",
        "            recs_at_k = set(recommended_items[:k])\n",
        "            \n",
        "            hit = 1 if len(recs_at_k & relevant_items) > 0 else 0\n",
        "            results['hit_rates'][k].append(hit)\n",
        "            \n",
        "            # Precision@K\n",
        "            precision = len(recs_at_k & relevant_items) / k if k > 0 else 0\n",
        "            results['precisions'][k].append(precision)\n",
        "            \n",
        "            # Recall@K\n",
        "            recall = len(recs_at_k & relevant_items) / len(relevant_items)\n",
        "            results['recalls'][k].append(recall)\n",
        "            \n",
        "            # NDCG@K\n",
        "            dcg = 0\n",
        "            idcg = sum([1/math.log2(i+2) for i in range(min(k, len(relevant_items)))])\n",
        "            for i, item in enumerate(recommended_items[:k]):\n",
        "                if item in relevant_items:\n",
        "                    dcg += 1 / math.log2(i + 2)\n",
        "            ndcg = dcg / idcg if idcg > 0 else 0\n",
        "            results['ndcg'][k].append(ndcg)\n",
        "        \n",
        "        if model_type == 'svd':\n",
        "            for _, row in user_test.iterrows():\n",
        "                pred = model.predict(user_id, row['asin'])\n",
        "                results['predictions'].append(pred)\n",
        "                results['actuals'].append(row['overall'])\n",
        "        \n",
        "        users_evaluated += 1\n",
        "    \n",
        "    print(f\"\\nSuccessfully evaluated {users_evaluated} users\")\n",
        "    \n",
        "    if model_type == 'svd' and len(results['predictions']) > 0:\n",
        "        rmse = math.sqrt(mean_squared_error(results['actuals'], results['predictions']))\n",
        "        mae = mean_absolute_error(results['actuals'], results['predictions'])\n",
        "        print(f\"\\nRating Prediction Metrics:\")\n",
        "        print(f\"  RMSE: {rmse:.4f}\")\n",
        "        print(f\"  MAE:  {mae:.4f}\")\n",
        "    \n",
        "    print(f\"\\nRanking Metrics:\")\n",
        "    for k in k_values:\n",
        "        if len(results['hit_rates'][k]) > 0:\n",
        "            hit_rate = np.mean(results['hit_rates'][k])\n",
        "            precision = np.mean(results['precisions'][k])\n",
        "            recall = np.mean(results['recalls'][k])\n",
        "            ndcg = np.mean(results['ndcg'][k])\n",
        "            \n",
        "            print(f\"\\n  @{k}:\")\n",
        "            print(f\"    Hit Rate:  {hit_rate:.4f}\")\n",
        "            print(f\"    Precision: {precision:.4f}\")\n",
        "            print(f\"    Recall:    {recall:.4f}\")\n",
        "            print(f\"    NDCG:      {ndcg:.4f}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing data for SVD...\n",
            "  Users: 933\n",
            "  Items: 823\n",
            "  Ratings: 1,089\n",
            "\n",
            "Training SVD model...\n",
            "  Latent factors: 5\n",
            "\n",
            " SVD model trained\n",
            "  User factors shape: (933, 5)\n",
            "  Item factors shape: (823, 5)\n",
            "\n",
            "Evaluating on 933 users\n",
            "\n",
            "Successfully evaluated 745 users\n",
            "\n",
            "Rating Prediction Metrics:\n",
            "  RMSE: 1.1020\n",
            "  MAE:  0.6658\n",
            "\n",
            "Ranking Metrics:\n",
            "\n",
            "  @5:\n",
            "    Hit Rate:  0.0027\n",
            "    Precision: 0.0005\n",
            "    Recall:    0.0027\n",
            "    NDCG:      0.0022\n",
            "\n",
            "  @10:\n",
            "    Hit Rate:  0.0054\n",
            "    Precision: 0.0005\n",
            "    Recall:    0.0054\n",
            "    NDCG:      0.0030\n",
            "\n",
            "  @20:\n",
            "    Hit Rate:  0.0161\n",
            "    Precision: 0.0008\n",
            "    Recall:    0.0161\n",
            "    NDCG:      0.0056\n",
            "\n",
            "Evaluating on 933 users\n",
            "\n",
            "Successfully evaluated 745 users\n",
            "\n",
            "Ranking Metrics:\n",
            "\n",
            "  @5:\n",
            "    Hit Rate:  0.0255\n",
            "    Precision: 0.0051\n",
            "    Recall:    0.0255\n",
            "    NDCG:      0.0185\n",
            "\n",
            "  @10:\n",
            "    Hit Rate:  0.0644\n",
            "    Precision: 0.0064\n",
            "    Recall:    0.0644\n",
            "    NDCG:      0.0309\n",
            "\n",
            "  @20:\n",
            "    Hit Rate:  0.0926\n",
            "    Precision: 0.0046\n",
            "    Recall:    0.0926\n",
            "    NDCG:      0.0382\n"
          ]
        }
      ],
      "source": [
        "svd_model = MatrixFactorizationSVD(n_factors=50)\n",
        "svd_model.fit(train_df)\n",
        "\n",
        "pop_model = PopularityRecommender()\n",
        "pop_model.fit(train_df)\n",
        "\n",
        "svd_results = evaluate_recommendations(\n",
        "    svd_model, \n",
        "    train_df, \n",
        "    test_df, \n",
        "    model_type='svd',\n",
        "    k_values=[5, 10, 20],\n",
        "    min_rating_threshold=3.5\n",
        ")\n",
        "\n",
        "pop_results = evaluate_recommendations(\n",
        "    pop_model,\n",
        "    train_df,\n",
        "    test_df,\n",
        "    model_type='popularity',\n",
        "    k_values=[5, 10, 20],\n",
        "    min_rating_threshold=3.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving models...\n",
            "  Saved: models/popularity_model.pkl\n",
            "  Saved: models/svd_model.pkl\n",
            "  Saved: models/content_model.pkl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "print(\"\\nSaving models...\")\n",
        "\n",
        "with open('models/popularity_model.pkl', 'wb') as f:\n",
        "    pickle.dump(pop_model, f)\n",
        "print(\"  Saved: models/popularity_model.pkl\")\n",
        "\n",
        "with open('models/svd_model.pkl', 'wb') as f:\n",
        "    pickle.dump(svd_model, f)\n",
        "print(\"  Saved: models/svd_model.pkl\")\n",
        "\n",
        "with open('models/content_model.pkl', 'wb') as f:\n",
        "    pickle.dump(content_model, f)\n",
        "print(\"  Saved: models/content_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving TF-IDF artifacts...\n",
            "  Saved: models/product_tfidf_vectorizer.pkl\n",
            "  Saved: models/product_tfidf_matrix.pkl\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSaving TF-IDF artifacts...\")\n",
        "with open('models/product_tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(product_tfidf, f)\n",
        "print(\"  Saved: models/product_tfidf_vectorizer.pkl\")\n",
        "\n",
        "with open('models/product_tfidf_matrix.pkl', 'wb') as f:\n",
        "    pickle.dump(product_tfidf_matrix, f)\n",
        "print(\"  Saved: models/product_tfidf_matrix.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Saved: models/user_to_idx.pkl\n",
            "  Saved: models/product_to_idx.pkl\n"
          ]
        }
      ],
      "source": [
        "with open('models/user_to_idx.pkl', 'wb') as f:\n",
        "    pickle.dump(user_to_idx, f)\n",
        "print(\"  Saved: models/user_to_idx.pkl\")\n",
        "\n",
        "with open('models/product_to_idx.pkl', 'wb') as f:\n",
        "    pickle.dump(product_to_idx, f)\n",
        "print(\"  Saved: models/product_to_idx.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving processed datasets...\n",
            "  Saved: data/processed/features_complete.csv\n",
            "  Saved: data/processed/train_set.csv\n",
            "  Saved: data/processed/test_set.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSaving processed datasets...\")\n",
        "df.to_csv('data/processed/features_complete.csv', index=False)\n",
        "print(\"  Saved: data/processed/features_complete.csv\")\n",
        "\n",
        "train_df.to_csv('data/processed/train_set.csv', index=False)\n",
        "test_df.to_csv('data/processed/test_set.csv', index=False)\n",
        "print(\"  Saved: data/processed/train_set.csv\")\n",
        "print(\"  Saved: data/processed/test_set.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
